import requests
from bs4 import BeautifulSoup
import http.server
import socketserver
import os

PORT = 8000


def fetch_cross_chapter(url):
    #Fetching of particular webpage at the given url
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    else:
        raise Exception(f"Failed to fetch page: {url}")


def parse_html(html):
    # this function used to parse html
    # function consists of one parameter, which is string containing raw html content
    soup = BeautifulSoup(html, 'html.parser')
    return soup



def clean_html(soup):
   #De-Gatsbyfication (cleaning inlines, unecessary containers, style tags)
    for div in soup.find_all('div', class_='unwanted-class'):
        div.decompose()  # Removes the tag completely

    # Remove inline <style> and <script> tags
    for tag in soup.find_all(['style', 'script']):
        tag.decompose()

    # Remove unnecessary containers
    for div in soup.find_all('div', recursive=False):
        if len(div.contents) == 1 and div.contents[0].name == 'div':
            div.unwrap()

    # Remove React-specific attributes
    for tag in soup.find_all(True):
        attrs_to_remove = [attr for attr in tag.attrs if attr.startswith('data-react')]
        for attr in attrs_to_remove:
            del tag[attr]

    # Simplify class names
    for tag in soup.find_all(True):
        if 'class' in tag.attrs:
            tag['class'] = [cls for cls in tag['class'] if 'autogenerated' not in cls]

    return soup



def add_ids(soup):
    # adding the ids
    for i, tag in enumerate(soup.find_all(['h1', 'h2', 'h3'])):
        tag['id'] = f"{tag.name}_{i + 1}"
    return soup


#Save or Display the the processed html
def save_html(soup, output_path):
    with open(output_path, 'w', encoding='utf-8') as file:
        file.write(soup.prettify())
    print(f"Processed HTML saved to: {output_path}")


# Using the actual URL of the chapter
url = "https://www.ipcc.ch/report/ar6/wg2/chapter/ccp7/"
html_content = fetch_cross_chapter(url)
soup = parse_html(html_content)
cleaned_soup = clean_html(soup)
final_soup = add_ids(cleaned_soup)
save_html(final_soup, "ar6_crosschapter_processed.html")

# Getting the file name from the directory
directory = os.getcwd()
files = [f for f in os.listdir(directory) if f.endswith(".html")]

if not files:
    print("No HTML files found in the current directory.")
    exit()

# Picking the first HTML file (or modify this to choose a specific one)
html_file = files[0]
url = f"http://localhost:{PORT}/{html_file}"


class Handler(http.server.SimpleHTTPRequestHandler):
    pass


with socketserver.TCPServer(("", PORT), Handler) as httpd:
    print(f"Serving {html_file} at {url}")
    print("Press Ctrl+C to stop the server.")
    httpd.serve_forever()
